---
title: "data_cleaning_inconsistencies_errors"
author: "Takeshi Stormer"
date: "2025-11-17"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

|                                              |
|:--------------------------------------------:|
| Project/scripts/data_cleaning_inconsistent.R |

Run:

```{r}
# Dependencies
library(arrow)
library(dplyr)

# Initializes and defines ad_data file.
# You will run into an error retrieving the data through this way since running code in an Rmd file changes what getwd() returns.
#---- Code you would use under normal conditions.
# base_data_path = file.path(getwd(), "Project/scripts/load_data.R")
# source(base_data_path)
#---- Newer code that you use for this R-markdown file.
base_data_path = file.path(dirname(getwd()), "data/bids_data_vDTR.parquet")
ad_data = arrow::read_parquet(base_data_path)
```

|                                        |
|:--------------------------------------:|
| PROJECT DATA CLEANER (inconsistencies) |

Purpose: - Document noticeable errors/inconsistency with data types, formatting, prior data modifications (some of the 12 bombs), and spelling mistakes to name a few.

**Note:** May otherwise miss some errors/inconsistencies.

|                                      |
|:------------------------------------:|
| NOTED ERRORS/INCONSITENCIES (KAN-18) |

Template: - [KEY(S)] \<DATATYPE(S)\>: Error\
+ Code\
+ [Optional: Note]

Errors/Inconsistencies:\
- PRICE <chr>: Should be of data type double.

```{r}
typeof(ad_data$PRICE)
```

\- DEVICE_GEO_ZIP <chr>: Should be of data type integer.

```{r}
typeof(ad_data$DEVICE_GEO_ZIP)
```

\- TIMESTAMP <chr>: Inconsistent formatting.

```{r}
print(c(ad_data$TIMESTAMP[1528], ad_data$TIMESTAMP[1], ad_data$TIMESTAMP[10]))
```

\- TIMESTAMP <chr>: Data set is not sorted chronologically.

```{r}
print(c(ad_data$TIMESTAMP[24], ad_data$TIMESTAMP[25]))
```

\- DEVICE_GEO_LONG <dbl>: There exists exactly 100 points that lie beyond the border of Oregon.

```{r}
print(filter(.data=ad_data, DEVICE_GEO_LONG < -130)$DEVICE_GEO_LONG, na.print='.')
print(length(filter(.data=ad_data, DEVICE_GEO_LONG < -130)$DEVICE_GEO_LONG))
```

**Note:** These points lie exactly 10 degrees to the west of corresponding city longitudinal values.\

\
- PRICE <chr>: There exist prices that are negative.

```{r}
filter(mutate(.data=ad_data, PRICE=ifelse(substr(PRICE, 1, 1) == "O", sub("^O", "0", PRICE), PRICE), PRICE=as.double(PRICE)), PRICE < 0)$PRICE
```

\- PRICE <chr>: There exist negative prices that have BID_WON==TRUE.

```{r}
select(.data=filter(mutate(.data=ad_data, PRICE=ifelse(substr(PRICE, 1, 1) == "O", sub("^O", "0", PRICE), PRICE), PRICE=as.double(PRICE)), PRICE < 0), PRICE, BID_WON)
```

\- PRICE <chr>: There exist prices that are close to -1000 (-999).

```{r}
select(.data=filter(mutate(.data=ad_data, PRICE=ifelse(substr(PRICE, 1, 1) == "O", sub("^O", "0", PRICE), PRICE), PRICE=as.double(PRICE)), PRICE < 0), PRICE, BID_WON)$PRICE[9]
```

\- BID_WON <chr>: Should be of data type logical.

```{r}
typeof(ad_data$BID_WON)
```

\- AUCTION_ID, BID_WON \<chr, chr\>: There are bids with multiple wins.

```{r}
filter(.data=summarise(.data=group_by(.data=ad_data, AUCTION_ID), won=sum(BID_WON=="TRUE"), lost=sum(BID_WON=="FALSE"), total=n()), won > 1)
```

**Note:** The existence of an auction have 6 winners can indicate that no shifting of columns occurred.
Furthermore, row with AUCTION_ID 188ce80a-9440-4a14-8c6f-00d7b9142bdd has 43 winning bids all priced at the same value.\

\
- TIMESTAMP, DATE_UTC \<chr, chr\>: TIMESTAMP does not reflect timezones properly according to locations (it's in UTC).

```{r}
select(.data=ad_data, TIMESTAMP, DATE_UTC)
```

**Note:** You can easily tell by comparing the day of the month between two times and recognize that it is taken in UTC (i.e., for the first entry, you can see that it is the 21st day of October, on the 23rd hour. If you add 8 hours to account for UTC converting from PST to UTC and you should be on the 22nd day. However, DATE_UTC reflects the 21st day as well. This is helpful since TIMESTAMP reflects UTC, which we can utilize to correctly index existing TIMESTAMP values.\
\
- DEVICE_GEO_REGION <chr>: Inconsistent formatting.

```{r}
unique(ad_data$DEVICE_GEO_REGION)
```

\- DEVICE_GEO_CITY <chr>: Existence of non-cities (unincorporated communities, CDPs, etc.).

```{r}
print(unique(ad_data$DEVICE_GEO_CITY), n=100, na.print=".")
```

**Note:** Most probably negligible.
Example of non-city: Rhododendron (is an unincorporated community).\

\
- DEVICE_GEO_ZIP <chr>: There exists a negative ZIP code (-999).

```{r}
filter(mutate(.data=ad_data, DEVICE_GEO_ZIP=as.double(DEVICE_GEO_ZIP)), DEVICE_GEO_ZIP < 0)$DEVICE_GEO_ZIP
```

\- RESPONSE_TIME <chr>: Should be of type integer.

```{r}
typeof(ad_data$RESPONSE_TIME)
```

**Note:** The last three-four characters in most cases should contain the desired information.\

\
- RESPONSE_TIME <chr>: Inconsistent formatting.

```{r}
print(c(unique(ad_data$RESPONSE_TIME)[727], unique(ad_data$RESPONSE_TIME)[1019]))
```

**Note:** There exists at least one RESPONSE_TIME value that has the following delimiter RESSPONSE_TIME (as opposed to RESPONSE_TIME).\

\
- REQUESTED_SIZE, SIZE \<chr, chr\>: There exists requested sizes of 0x0 and 1x1 that also do not meet requested size specifications despite have BID_WON==TRUE

```{r}
select(.data=filter(.data=ad_data, (SIZE=="0x0" | SIZE=="1x1"), BID_WON=="TRUE"), SIZE, BID_WON)
```

**Note:** We would not be able to determine the actual size won for these invalid SIZE values if REQUESTED_SIZE contains more than 2 requested sizes.

|                           |
|:-------------------------:|
| Tested for / other notes: |

-   Multiple time entries for distinct AUCTION_ID.\
-   Pattern in inconsistent formatting for TIMESTAMP\
-   Could be an issue with it being not in chronological order (error applied before scrambling).\
-   Noted that some cities encompass more than 20 zip codes in DEVICE_GEO_ZIP and DEVICE_GEO_ZIP - Noted that at least some AUCTION_ID values are encompassed purely by one bider in PUBLISHER_ID (one bider bidding multiple times).\
-   For further exploration, we can potentially re-order these instances in chronological order by RESPONSE_TIME

|                                                                 |
|:---------------------------------------------------------------:|
| DETERMINATION OF IMPORTANCE FOR ERRORS/INCONSISTENCIES (KAN-19) |

Template: - [KEY(S)] \<DATATYPE(S)\> \<IMPORTANCE LEVEL in \*'s\> \<✔️ if implemented fix\>\
+ Notes on importance.

Importance:\
- PRICE <chr> \<\*\*\*\*\*\> ✔️\
**Note:** For ease of data processing, I believe that converting the column price in type double (after ensuring that all values follow a double type [i.e. no "five point eight" or "O.340000" values]) will be highly beneficial.\

\
- PRICE <chr> \<\*\*\*\*\*\> ✔️\
**Note:** Removing outliers (negative values) will improve accuracy, therefore we should look to remove negative values as there is appears to be no pattern that would allow us to recover the underlying data without introducing error.\

\
- DEVICE_GEO_ZIP <chr> \<\*\*\*\*\*\> ✔️\
**Note:** The more numerical values we have, the easier it would be for us to find patterns we otherwise couldn't see.\

\
- DEVICE_GEO_ZIP <chr> \<\*\*\*\*\*\> ✔️\
**Note:** Removing outliers (negative values) will improve accuracy.
We could not effectively deduce what value of DEVICE_GEO_ZIP based on DEVICE_GEO_CITY (Portland contains multiple ZIP codes, majority if not all -999 ZIP code values are from Portland).\

\
- TIMESTAMP <chr> \<\*\*\*\*\> ✔️\
**Note:** Providing a consistent formating for TIMESTAMP would allow for ease of conversion into numerical representation.\

\
- TIMESTAMP <chr> \<\*\*\*\>\
**Note:** Sorting TIMESTAMP into chronological order would allow for the creation of parameters that are typically seen in time-series data (moving averages, lag, etc.).
However given we have 400k+ rows of data (\~100k+ rows if you collapse by AUCTION_ID and BID_WON), it will take a while to sort.\

\
- BID_WON <chr> \<\*\>\
**Note:** Converting BID_WON into type logical would not really make a difference as we can easily query through the three existing unique values of TRUE, true, and FALSE.\

\
- DEVICE_GEO_LONG <dbl> \<\*\*\*\> ✔️\
**Note:** Given that only 100 data points out of the 400k+ contain invalid longitudinal points, these points can be thrown out.
It is also easily deducible that these 100 points are exactly 10 degrees further to the west than their respective counterparts (when sorted by DEVICE_GEO_CITY, DEVICE_GEO_ZIP and DEVICE_GEO_LONG).\

\
- AUCTION_ID, BID_WON \<chr, chr\> \<\*\*\*\*\>\
**Note:** Deducing whether or not it's possible for an auction to have multiple winners is going to be relatively important.
If we deduce it is not important, there is no effective way of determining which bid actually won, and therefore we can throw them out.\

\
- DEVICE_GEO_REGION <chr> \<\*\> ✔️\
**Note:** We know that this data exclusively comes from Oregon, therefore we can just set all values to Oregon (or OR).\

\
- DEVICE_GEO_CITY <chr> \<\>\
**Note:** I don't see why we would remove non-cities from DEVICE_GEO_CITY.
Maybe a name change for the column would better reflect the data.\

\
- RESPONSE_TIME <chr> \<\*\*\*\*\*\> ✔️\
**Note:** Formatting then converting RESPONSE_TIME into type integer would improve accuracy.\

\
- REQUESTED_SIZE, SIZE \<chr, chr\> \<\*\*\*\*\*\> ✔️\
**Note:** Establishing correct SIZE values along with converting REQUESTED_SIZE back into an character array would allow us to establish select parameters like Price Per Pixel (price / width \* height).
